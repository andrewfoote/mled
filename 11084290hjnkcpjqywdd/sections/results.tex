\subsection{Enrollment and Completions}

Table \ref{tab:main} shows  results for the main outcomes. The top panel shows results for community colleges and the lower panel shows the same specifications for for-profit colleges. The first column shows that a one percent increase in the number of workers laid off leads to a 0.015 percent increase in community college enrollment, with a smaller effect in subsequent years. The second column displays fall enrollment just among first-time students. We expect this response to be more pronounced than for overall enrollment, because overall enrollment includes continuing students. Indeed, the estimates in the second column of the table are slightly larger than the first column, although the difference is not statistically significant. 

The second panel of the table suggests that for-profit institutions also see positive enrollment effects of a similar magnitude. However, the results are smaller than for community colleges and not statistically significant. While the for-profit sector is a fraction of the size of the public sector, and is likely underrepresented in the IPEDS data, this is still suggestive evidence of a response. However, we certainly do not find any evidence that for-profit enrollments are responding in an outsize way relative to community colleges.

The next four columns of Table \ref{tab:main} explore the effect of layoff shocks on degree receipt. We expect the measured effects to be more muted than for enrollment, because of high attrition rates in the two-year sector, as well as the lag between enrollment and degree completion \citep{CBJK2008}. Still, the third column shows that degree and certificate receipt does respond to layoffs. A one percent increase in layoffs results in a 0.017 percent increase in community college awards two years later, and a 0.004 percent increase three years later. There is a smaller effect at the for-profit level.  Perhaps not surprisingly, the larger effect are for smaller certificate programs that take less time to complete, and also have fewer general education requirements than associate degree programs. 

The timing of the award response is not immediate. At the community college level, the timing is consistent with the length of time required to finish these programs. For example, the effect on the completion of associate's degrees, which take approximately two years of full-time study, is concentrated in the two-year lag, although not statistically significant. Completion of certificates is evenly distributed across all years. 


At the for-profit level, the results are much less precise. There is not a significant increase in associate's degrees following layoffs, as the bulk of for-profit awards are concentrated among shorter-term certificates. We find a large and statistically significant response for certificates only in the third lag. We find large responses for very short certificates at the second and third lags. In general, the main results for for-profit colleges are intuitive. However, given our lack of precision in these estimates, as well as restraint in the general literature on relying too much on for-profit college statistics in the IPEDS data, we focus on community colleges for the remainder of the paper. 

The main result from Table \ref{tab:main} is that there is a positive and statistically significant effect of mass layoffs on enrollment and completion in community colleges. To scale these effects, consider a commuting zone at the mean of the mass layoffs distribution. For 100 workers involved in a mass layoff in this commuting zone, our estimates suggest that first-time enrollment increases by approximately 2.8 students within three years. Moreover, eventual degree receipt increases by 1.9 students over the same period. 

In related work using a similar methodology, sample, and time period, we find that a one percentage point increase in the share of the labor force laid off leads to a 0.2 percentage point decrease in the size of the labor force, of which only half can be explained through observable channels such as migration, retirement, and enrollment in disability insurance \citep{FGS2015}. Our results on enrollment suggest that about half the workers exiting the labor force not through these channels are accounted for by increases in community college enrollment. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Field of Study}
Next we estimate the differential responses for degree and certificate production by field of study. Ideally, we would be able to observe enrollment in different types of degree and certificate programs. Identifying which student is enrolled in a particular program, though, is particularly difficult \citep{BSZ2015}. We can only observe completion by program of study, which incorporates a certain measure of endogenous differences in completion rates. Nevertheless, in all cases we expect our estimates of the effect of mass layoffs on program-level completions to be an underestimate, both in terms of the absolute magnitude as well as in the speed of response. Thus, we believe measuring completion can shed light on how workers are responding to displacement.

The first column of Table \ref{tab:mainbyprog} shows the aggregate award response, by type of award. These awards encompass career-technical programs as well as academic programs for students aiming to transfer. In the second column we observe the response just for career-technical programs. Not surprisingly, the results are stronger for CTE awards at all levels, given that displaced workers are likely to enroll in these programs in order to upgrade their skills. 

Columns 3-7 further disaggregate the career-technical awards by the specific content of the programs. We find a large and statistically significant increase in the production of awards in construction and manufacturing fields following layoffs, especially for associate's degrees. This is perhaps surprising given the contemporaneous decline of manufacturing. However, there are a few potential explanations. First, workers laid off in mass layoff events are more likely to be in manufacturing and production fields,  making them also more likely to retrain in manufacturing fields. Second, aggregating all programs of this type ignores the fact that much of the response may be in certain high-growth areas. In fact, in recent years funding from large federal programs such as Trade Adjustment Assistance (TAA) and the Workforce Investment and Opportunity Act (WIA) has gone specifically to high-tech manufacturing programs \citep{wioa2014, eyster2017taaccct}. We return to this issue in the next subsection.

The fourth column of the table examines health programs, which shows a large and statistically significant effect on degree receipt in health programs. In particular, we find the strongest effects for short-term certificates, as opposed to associate's degrees or even long-term certificates. Small certificates grow almost 0.06 percent in the first year following a one percent increase in layoffs. These small certificates are generally for medical assisting, nursing assisting, and related fields. Prior research has found that employment in these occupations is highly countercyclical \citep{SMPF2015, BS2012},\footnote{There are many reasons for why employment in these occupations is countercyclical: they tend to be low-income, provide low-benefits, with high turnover, low job stability, and high levels of stress \citep{BH1996, Yamada2002}.} and our results suggest that training for these occupations is also counteryclical. On the other hand, it is not surprising that we find little effect for associate's degree and long-term certificates programs. These programs tend to be oversubscribed and face large capacity constraints, so it is unlikely that additional student demand following layoff events would lead to increases in enrollment and completion in these programs \citep{Kuehn2007}.

Column 5 shows the effects for information technology programs. The main effect seems to be concentrated in increases in associate's degree completions. Given that many information technology programs focus on  degrees rather than certificates, this result makes sense. In contrast, there is very little evidence that workers enroll in public and protective services like fire, police academy and corrections, as shown in column 6.  While one coefficient is large and significant, every other coefficient is smaller than for the other fields and not statistically significant. 

Finally, we examine childcare and cosmetology.\footnote{We examine these two types of programs together because they are both lower-skill service occupations with low economic returns \citep{SKG2014}.} Overall, we find negative and statistically insignificant results. However, we do find a large increase in the production of certificates at a three year lag, which reflects  the structure of this particular sector. The bulk of childcare and cosmetology awards are in certificates, and workers in these fields tend to need to earn small one-semester certificates in order to maintain their licenses and credentials. Thus, the fact that we do not see any response in smaller certificates suggests that the effect is driven by students gaining new credentials as opposed to re-certifying existing ones. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Degree Receipt Response by Expected Earnings Returns}
So far, we have documented heterogeneity in the educational production response to mass layoffs that depends on field of study. An important question is whether the fields that see the largest responses are the ones with the greatest earnings potential. A number of recent papers have measured the labor market returns to different two-year programs and found a great deal of heterogeneity across field of study \citep{SKG2014, JTC2014, BLT2014}. Likewise, how students select into different programs of study is still an open question: there is limited evidence that four-year college and community college students incorporate expected earnings returns into their choice of field  \citep{bakereffect, arcidiacono2012modeling, wiswall2015determinants}. Thus, it is important to understand whether, when faced with dire employment prospects, workers sort into fields with high earnings potential. 

For this exercise we estimate our main results for programs at the four-digit CIP code level, which is a much more detailed description of programs than the two-digit codes we display in Table \ref{tab:mainbyprog}. We then match these four-digit CIP code results to program-level earnings returns in \citet{SKG2014}, who use comparable four-digit program codes.\footnote{The estimates in \citet{SKG2014} come from California community colleges, though the results are broadly similar as estimates in other states \citep{BB2017}.}  Most of the CIP codes match to the coefficients reported in \citet{SKG2014}, but in cases where there is no observed coefficient we do not estimate a layoff response. \citet{SKG2014} disaggregate degrees based on units required, while we only have years required for certificates (one to four years  or less than one year). To harmonize these definitions, we average the 30-59 and 18-29 unit effects from their paper and treat that as the estimate for the one to four year certificate. 

Figure \ref{fig:scatterallsmall} shows a scatter plot of the layoff response magnitudes (vertical axis) with the estimated return for that field and degree (horizontal axis). In panels (a) and (b) of Figure \ref{fig:scatterallsmall}  the size of the dots correspond to the average annual  completions in that field and award type nationwide. Panel (a) shows that there  is a weak yet  positive correlation between the measures: a regression line through these data has a coefficient of 0.012 (0.01). In panel (b) we omit all statistically insignificant estimates of earnings returns. This does not substantially change the result: the relationship is still positive, although more precisely estimated.\footnote{The regression coefficient becomes 0.026 (0.014).} Panels (c) and (d) show the same data, with the dots in different colors corresponding to the type of degree or certificate. The positive association between earnings returns and completion effects following layoffs is not necessarily limited to a particular type of award: degrees and certificates all had positive associations even though degrees tended to have larger earnings returns than certificates. 

These analyses show that there are considerable differences in the field of study workers enter following local downturns, and suggestive evidence that there are larger responses for fields with higher labor market returns. This is an optimistic finding for those concerned about the role community colleges play in helping labor markets adjust in the long term. However, one broader concern is that students may not be able to enroll in high-demand, high-return programs if these programs are capacity constrained, which means the true demand for these programs is actually higher.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Other Findings}
Given previous work that finds larger non-participation responses during the Great Recession, we may expect larger enrollment effects in this period. To estimate the size of the difference, we allow the effect of a mass layoff to differ for the years before and after the start of the  Great Recession in 2007. Our results, in Table \ref{tab:mainrece}, show minimal differences between the two periods, which suggests that the increased non-participation did not result in larger enrollment responses.\footnote{Table \ref{tab:field_recession} shows results by field of study, with similar results as in Table \ref{tab:main}.}  However, one reason for this effect may have been decreases in availability of community college, as funding levels fell during the Great Recession as well. 

It is also important to understand the effects of specific policies that target education for unemployed and displaced workers. In a study of the effect of unemployment insurance (UI) policies on four-year college enrollment, \citet{BT2015} show larger effects in states with more inclusive regulations about the types of coursework UI beneficiaries could take without losing benefits. In particular, they focus on states that allowed beneficiaries to enroll in academic courses not related to a particular vocational program. Following \citet{BT2015}, we use this categorization of states and allow the main effect in our analysis to vary for states with approved and non-approved academic courses.\footnote{Specifically, the map in Figure 2.} Table \ref{tab:mainuibt} shows the coefficients on these interactions. There is a large and positive effect on new enrollments in the first lag for states with approved academic coursework for UI beneficiaries. This is consistent with the results in \citet{BT2015} for four-year college enrollment. However, we find no differential effect for overall degree completion, as shown in the last columns of the table. Other federal workforce policies with education provisions, such as Trade Adjustment Assistance (TAA) and the Workforce Investment Act (WIA), likely have even larger impact. It is outside the scope of this paper to study their effects, though. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Robustness Checks \label{sec:robchecks}}
We perform a number of robustness checks for the main results. First, Table \ref{tab:firstmain} shows that the main estimates are not sensitive to the inclusion of additional lags, and that the largest effects are completed by the third lag. Moreover, the last column of the table shows that not accounting for local area trends leads to substantially different results. 


The next check is with respect to the main analytical method.  \citet{Basso2016} shows that there is some concern that distributed lag models, like our main estimating Equation \ref{eqn:main}, can be biased in the presence of autocorrelation. To ensure that our results are robust  to addressing this concern, we also estimate our results using local projections, which can be readily adapted to this type of analysis \citep{Jorda2005, Basso2016}. We estimate a function of the following form: 
\begin{equation}
ln(y_{c,t+s})-ln(y_{c,t-1})=\gamma_s \Delta M_{ct}+\sum_{i=1}^s{(X'_{c,t-i}\delta_{si})}+\alpha_c+\zeta_t+u_{c,t+s}
\label{eqn:localproj}
\end{equation}

An important component of Equation \ref{eqn:localproj} is that it controls for intermediate values of the explanatory variables $X_{c,t-i}$ for years $i$ between $t$ and $t+s$. Moreover, we control for commuting zone fixed effects $\alpha_c$ which, because of the first difference, are effectively controlling for local trends. The specification also includes year fixed effects $\zeta_t$.  The estimation technique is particularly useful in settings, like this one, where the effect may take time to fully propogate.\footnote{There are a few other benefits to using this method over estimates like Equation \ref{eqn:main}. First, the identification assumption is similar to what we have been estimating until now: mass layoffs are exogenous to enrollment  conditional on local trends and time fixed effects. Thus, inference is straightforward. Essentially, as noted by \citet{Basso2016}, equation \ref{eqn:localproj} is an adaptation of a typical event study framework as used in the general applied microeconomics literature, but where the shock is continuous and the event is not a one-time occurrence. Furthermore, local projections of this type are relatively straightforward to implement using standard regression packages, and adapt easily to the panel structure of the dataset. } 

Figure \ref{fig:czlproj} plots estimates of equation \ref{eqn:localproj} for different values of lags $s$. Overall we find that the local projections have less precision than the previously shown estimates. However,  the results are qualitatively similar. Panel (a) shows that fall enrollment grows for the three years after a layoff event. The estimates for first-time fall enrollment, as before, are stronger and suggest an immediate effect that then persists until the third year. 

Our next robustness check is to estimate our main regression equation, but using counties rather than commuting zones as our area of study. In Appendix Table \ref{tab:maincou} we show results using counties as the definition of local labor markets. The results are  similar to the main results using commuting zones, which confirms that our results are not driven by the level of geography chosen. The effects are more muted, however, because many counties do not have a postsecondary institution even though they experience layoffs: the analysis at the county level drops these counties. Figure \ref{fig:colproj} displays the local projections estimates of Equation \ref{eqn:localproj}, but at the county level; these results are similar to those at the commuting zone level. The estimates for enrollment in panels (a) and (b) are almost identical. However, the estimates for production of degrees and certificates are more similar to our main results: panel (c) shows that there is an immediate and sustained increase in overall degrees and certificates. Associate's degrees increase, especially by the third year. There is a weaker yet noticeable increase in the production of certificates as well. In sum, results from the local projections strategy are quite similar to the main results. 

%I think we should cut this paragraph.
We also test if there are heterogeneous effects by race and gender, and do not find any differences. These results are in Table \ref{tab:genderrace}, and suggest that the effects are quite similar across demographic groups. In Table \ref{tab:withdemogs} we show that our results are also not sensitive to the inclusion of local demographic variables.\footnote{Specifically we include the race composition of the commuting zone, with the share of the population under 18, 18-29, 30-44, 45-54, and over 55. We also include the number of postsecondary institutions.} 

%Additional paragraphs.

As a final check, we test whether our main results are sensitive to alternative definitions of commuting zones. Commuting zones are often used as proxies for local labor markets, collections of counties meant to capture distinct areas of economic activity. However, there are concerns  about underlying survey error in the commuting flows data \citet{TS1996} originally used to construct them.\footnote{ The commuting zone definitions by \citet{TS1996} are based on 1990 Journey to Work Data from the Decennial Census, which has underlying survey error. \citet{FKV2017} show that if one resamples from the implied distribution for each county-to-county flow and re-run the procedure, the commuting zone definitions differ substantial, re-assigning an average of 5\% of the population.} \citet{FKV2017} propose a test to address the uncertainty inherent in commuting zone definitions, by creating 1000 different commuting zone definitions based on resampling the underlying county-to-county migration flows using the \citet{TS1996} methodology. The test consists of using  all these realizations to re-estimate regression coefficients and standard errors, and using the resulting distribution of t-statistics to assess if a coefficient is robust to this uncertainty. Specifically, to assess if a coefficient is significant at the 5 percent level, the interval between the 2.5th and 97.5th percentiles of the t-statistic distribution should  not intersect with the interval (-1.96,1.96). 

Table \ref{tab:FKVtest} shows the results of such a test, for our main outcomes. For each lag of the layoff variable, we show the interval between the 2.5th and 97.5th percentile of the distribution of t-statistics created by running our results on the 1000 commuting zone definitions. The results on first-time enrollment in the second and third lags are robust to this test, as are the results on total degrees and certificates. 
